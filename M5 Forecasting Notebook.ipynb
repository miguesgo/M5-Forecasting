{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e36486",
   "metadata": {},
   "source": [
    "# Walmart Sales Analysis and Insights (M5 Dataset)\n",
    "**Autor:** Miguel Ángel  \n",
    "**Fecha:** Septiembre 2025  \n",
    "\n",
    "Exploratory Data Analysis (EDA) of Walmart sales data (M5 dataset). The notebook covers data cleaning, SQL-based queries, and Python visualizations to uncover insights on sales performance across stores, categories, and time periods.\n",
    "\n",
    "The analysis focuses on:\n",
    "- Data modeling and preparation  \n",
    "- SQL queries for key business insights  \n",
    "- Python visualizations (pandas, matplotlib)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce54f779",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc as db\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77681645",
   "metadata": {},
   "source": [
    "## 2. Data Integrity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7f0ca",
   "metadata": {},
   "source": [
    "The original sales_train_validation.csv file contains daily sales data for each product and store, where each day *(d_1 … d_1913)* is represented as a separate column. To facilitate analysis, the table was reshaped from a wide format to a long format using the melt function. In the transformed table *(sales_long)*, each row now represents a unique combination of product, store, and day (d), with the corresponding number of units sold. This structure makes it easier to perform aggregations, joins with the calendar and price tables, and time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_original = pd.read_csv(\"sales_train_validation.csv\")\n",
    "id_columns = [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\"]\n",
    "value_columns = [c for c in sales_original.columns if c.startswith(\"d_\")]\n",
    "\n",
    "sales_formatted = sales_original.melt(\n",
    "    id_vars = id_columns,\n",
    "    value_vars = value_columns,\n",
    "    var_name = \"d\",   \n",
    "    value_name = \"sales\"\n",
    ")\n",
    "\n",
    "sales_formatted.to_csv(\"sales_formatted.csv\", index=False)\n",
    "## Execution time: 1m 27s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3e805",
   "metadata": {},
   "source": [
    "The calendar dataset includes two sets of event columns *(event_name_1, event_type_1 and event_name_2, event_type_2)* because a single day may have multiple events *(e.g., Super Bowl and Cinco de Mayo on the same day)*.\n",
    "In this analysis, I kept the dataset in its original form for simplicity and because it does not affect data integrity. However, as a potential improvement, these event columns could be normalized into a separate table with one event per row, making the analysis of multiple events on the same day easier and more scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265eb89",
   "metadata": {},
   "source": [
    "### Importing CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7dfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv(\"calendar.csv\")\n",
    "sales_formatted = pd.read_csv(\"sales_formatted.csv\")\n",
    "sell_prices = pd.read_csv(\"sell_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze general structure\n",
    "calendar.info()\n",
    "sales_formatted.info()\n",
    "sell_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf96e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing null data\n",
    "calendar.isnull().sum() # -> Only nulls in events\n",
    "sales_formatted.isnull().sum() # -> Not nulls\n",
    "sell_prices.isnull().sum() # -> Not nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ffe901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing duplicated data\n",
    "calendar.duplicated().sum() # -> There's no duplicated data\n",
    "sales_formatted.duplicated().sum() # -> There's no duplicated data\n",
    "sell_prices.duplicated().sum() # -> There's no duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating keys and relationships\n",
    "sales_formatted.set_index([\"store_id\", \"item_id\", \"d\"]).index.is_unique # -> There's no duplicated data that violate ingregity\n",
    "sell_prices.set_index([\"store_id\", \"item_id\", \"wm_yr_wk\"]).index.is_unique # -> There's no duplicated data that violate ingregity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing range and logic values\n",
    "(sales_formatted[\"sales\"] < 0).sum() # -> No negative salea\n",
    "(sell_prices[\"sell_price\"] < 0).sum() # -> No negative prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing date types\n",
    "calendar[\"date\"].min(), calendar[\"date\"].max() # ('2011-01-29', '2016-06-19')\n",
    "len(calendar) # -> 1969 days in the record\n",
    "calendar.groupby(\"wm_yr_wk\")[\"d\"].count().value_counts().head()\n",
    "# 281 commercial weeks of 7 days and 1 week of just two days (the first week of the record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5159a",
   "metadata": {},
   "source": [
    "## 3. Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = db.connect(\"DRIVER={ODBC Driver 17 for SQL Server};SERVER=MIGUESGO;DATABASE=M5_Forcasting;Trusted_Connection=yes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2e231",
   "metadata": {},
   "source": [
    "## 4. Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9682ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pruducts sold in all the period\n",
    "query = \"\"\"\n",
    "    SELECT SUM(sales) AS unidades_vendidas\n",
    "    FROM dbo.sales_formatted;\n",
    "\"\"\"\n",
    "\n",
    "unidades_vendidas = pd.read_sql(query, connection)\n",
    "unidades_vendidas # 65,695,409 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales in all the period\n",
    "query = \"\"\"\n",
    "    SELECT SUM(S.sales * SP.sell_price) AS total_revenue\n",
    "    FROM dbo.sales_formatted AS S\n",
    "    JOIN dbo.calendar AS C ON S.d = C.d\n",
    "    JOIN dbo.sell_prices AS SP\n",
    "        ON SP.item_id = S.item_id\n",
    "        AND SP.store_id = S.store_id\n",
    "        AND SP.wm_yr_wk = C.wm_yr_wk;\n",
    "\"\"\"\n",
    "\n",
    "total_revenue = pd.read_sql(query, connection)\n",
    "float(total_revenue[\"total_revenue\"]) # -> $ 187,676,570.01990828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products sold per year in millions\n",
    "query = \"\"\"\n",
    "    SELECT C.year,\n",
    "\t   SUM(S.sales) AS total_sales_by_year\n",
    "    FROM dbo.sales_formatted AS S\n",
    "    JOIN dbo.calendar AS C ON C.d = S.d\n",
    "    GROUP BY C.year\n",
    "    ORDER BY C.year\n",
    "\"\"\"\n",
    "total_sales_by_year = pd.read_sql(query, connection)\n",
    "total_sales_by_year[\"total_sales_by_year\"] = (\n",
    "    round(total_sales_by_year[\"total_sales_by_year\"] / 1000000, 2)\n",
    ")\n",
    "print(total_sales_by_year)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.plot(total_sales_by_year[\"year\"],\n",
    "        total_sales_by_year[\"total_sales_by_year\"],\n",
    "        marker=\"o\",\n",
    "        linestyle=\"-\",\n",
    "        color=\"#5DA365\")\n",
    "for x, y in zip(total_sales_by_year[\"year\"], total_sales_by_year[\"total_sales_by_year\"]):\n",
    "    ax.text(x, y, f\"{y:,}\", ha=\"center\", va=\"bottom\", fontsize=12)\n",
    "ax.set_title(\"Products sold per year in millions\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Products sold\")\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2387f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total revenue per year in millions\n",
    "query = \"\"\"\n",
    "    SELECT C.year,\n",
    "        SUM(S.sales * SP.sell_price) AS total_revenue\n",
    "    FROM dbo.sales_formatted AS S\n",
    "    JOIN dbo.calendar AS C ON C.d = S.d\n",
    "    JOIN dbo.sell_prices AS SP\n",
    "        ON SP.store_id = S.store_id\n",
    "        AND SP.item_id = S.item_id\n",
    "        AND SP.wm_yr_wk = C.wm_yr_wk\n",
    "    GROUP BY C.year;\n",
    "\"\"\"\n",
    "total_revenue = pd.read_sql(query, connection)\n",
    "total_revenue[\"total_revenue\"] = (\n",
    "    round(total_revenue[\"total_revenue\"] / 1000000, 2)\n",
    ")\n",
    "print(total_revenue)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.plot(total_revenue[\"year\"],\n",
    "        total_revenue[\"total_revenue\"],\n",
    "        marker=\"o\",\n",
    "        linestyle=\"-\",\n",
    "        color=\"#59C5FF\")\n",
    "for x, y in zip(total_revenue[\"year\"], total_revenue[\"total_revenue\"]):\n",
    "    ax.text(x, y, f\"{y:,}\", ha=\"center\", va=\"bottom\", fontsize=12)\n",
    "ax.set_title(\"Total revenue per year in millions ($)\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Sales\")\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa17a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Product that sold more units per store\n",
    "query = \"\"\"\n",
    "    WITH total_sales_from_item AS (\n",
    "        -- Total sales from every item in all stores\n",
    "        SELECT store_id,\n",
    "            item_id,\n",
    "            SUM(sales) AS total_sales\n",
    "        FROM dbo.sales_formatted\n",
    "        GROUP BY store_id, item_id\n",
    "    ), max_sales_from_store AS (\n",
    "        -- Max sales from every store\n",
    "        SELECT store_id,\n",
    "        MAX(total_sales) as max_sales\n",
    "        FROM total_sales_from_item\n",
    "        GROUP BY store_id\n",
    "    )\n",
    "    SELECT TS.store_id,\n",
    "        TS.item_id,\n",
    "        MS.max_sales\n",
    "    FROM total_sales_from_item AS TS\n",
    "    JOIN max_sales_from_store AS MS\n",
    "        ON TS.store_id = MS.store_id\n",
    "        AND TS.total_sales = MS.max_sales\n",
    "    ORDER BY store_id;\n",
    "\"\"\"\n",
    "total_sales_from_item = pd.read_sql(query, connection)\n",
    "total_sales_from_item[\"store_item\"] = (\n",
    "    total_sales_from_item[\"store_id\"] + \" - \" + total_sales_from_item[\"item_id\"] \n",
    ")\n",
    "print(total_sales_from_item[[\"store_item\", \"max_sales\"]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "bars = ax.barh(total_sales_from_item[\"store_item\"],\n",
    "               total_sales_from_item[\"max_sales\"],\n",
    "               color=\"#5DA365\")\n",
    "ax.bar_label(bars, padding=3, fmt=\"%.0f\")\n",
    "ax.set_title(\"Products that sold more units per store\")\n",
    "ax.set_xlabel(\"Units sold\")\n",
    "ax.set_ylabel(\"Store - Product\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ecace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Product that sold more items per department\n",
    "query = \"\"\"\n",
    "    WITH total_sales_by_product AS (\n",
    "        -- total sales by product overall\n",
    "        SELECT dept_id,\n",
    "            item_id,\n",
    "            SUM(sales) AS total_sales\n",
    "        FROM dbo.sales_formatted\n",
    "        GROUP BY dept_id, item_id\n",
    "    ), max_sales AS (\n",
    "        SELECT dept_id,\n",
    "            MAX(total_sales) AS max_sales\n",
    "        FROM total_sales_by_product\n",
    "        GROUP BY dept_id\n",
    "    )\n",
    "    SELECT TS.dept_id,\n",
    "        TS.item_id,\n",
    "        MS.max_sales\n",
    "    FROM total_sales_by_product AS TS\n",
    "    JOIN max_sales AS MS\n",
    "        ON TS.dept_id = MS.dept_id\n",
    "        AND TS.total_sales = MS.max_sales\n",
    "    ORDER BY dept_id;\n",
    "\"\"\"\n",
    "\n",
    "total_sales_by_product = pd.read_sql(query, connection)\n",
    "total_sales_by_product[\"dept_item\"] = (\n",
    "    total_sales_by_product[\"dept_id\"] + \" - \" + total_sales_by_product[\"item_id\"]\n",
    ")\n",
    "print(total_sales_by_product[[\"dept_item\", \"max_sales\"]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(total_sales_by_product[\"dept_item\"],\n",
    "               total_sales_by_product[\"max_sales\"],\n",
    "               color=\"#59C5FF\")\n",
    "ax.bar_label(bars, padding=3, fmt=\"%.0f\")\n",
    "ax.set_title(\"Product that sold more per departament\")\n",
    "ax.set_xlabel(\"Units sold\")\n",
    "ax.set_ylabel(\"Departament - Product\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Product that sold more units per category\n",
    "query = \"\"\"\n",
    "    WITH total_sales_by_product AS (\n",
    "        -- total sales by product overall\n",
    "        SELECT cat_id,\n",
    "            item_id,\n",
    "            SUM(sales) AS total_sales\n",
    "        FROM dbo.sales_formatted\n",
    "        GROUP BY cat_id, item_id\n",
    "    ), max_sales AS (\n",
    "        SELECT cat_id,\n",
    "            MAX(total_sales) AS max_sales\n",
    "        FROM total_sales_by_product\n",
    "        GROUP BY cat_id\n",
    "    )\n",
    "    SELECT TS.cat_id,\n",
    "        TS.item_id,\n",
    "        MS.max_sales\n",
    "    FROM total_sales_by_product AS TS\n",
    "    JOIN max_sales AS MS\n",
    "        ON TS.cat_id = MS.cat_id\n",
    "        AND TS.total_sales = MS.max_sales\n",
    "    ORDER BY cat_id;\n",
    "\"\"\"\n",
    "\n",
    "total_sales_by_product = pd.read_sql(query, connection)\n",
    "total_sales_by_product[\"cat_item\"] = (\n",
    "    total_sales_by_product[\"cat_id\"] + \" - \" + total_sales_by_product[\"item_id\"]\n",
    ")\n",
    "print(total_sales_by_product[[\"cat_item\", \"max_sales\"]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(total_sales_by_product[\"cat_item\"],\n",
    "               total_sales_by_product[\"max_sales\"],\n",
    "               color=\"#5DA365\")\n",
    "ax.bar_label(bars, padding=3, fmt=\"%.0f\")\n",
    "ax.set_title(\"Product that sold more per category\")\n",
    "ax.set_xlabel(\"Units sold\")\n",
    "ax.set_ylabel(\"Category - Product\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top thre products per store\n",
    "query = \"\"\"\n",
    "    -- TOP 3 products that sold more units by store\n",
    "    WITH top_three_products AS (\n",
    "        SELECT store_id,\n",
    "            item_id,\n",
    "            SUM(sales) AS total_sales,\n",
    "            ROW_NUMBER() OVER (\n",
    "                    PARTITION BY store_id\n",
    "                    ORDER BY SUM(sales) DESC\n",
    "            ) AS rn\n",
    "        FROM dbo.sales_formatted\n",
    "        GROUP BY store_id, item_id\n",
    "    )\n",
    "    SELECT store_id,\n",
    "        item_id,\n",
    "        total_sales\n",
    "    FROM top_three_products\n",
    "    WHERE rn <= 3\n",
    "    ORDER BY store_id, rn\n",
    "\"\"\"\n",
    "\n",
    "top_three_products = pd.read_sql(query, connection)\n",
    "print(top_three_products.head())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "pivot = top_three_products.pivot(index=\"store_id\",\n",
    "                                 columns=\"item_id\",\n",
    "                                 values=\"total_sales\")\n",
    "pivot.plot(kind=\"bar\", ax=ax)\n",
    "\n",
    "ax.set_title(\"Top 3 products sold per store\")\n",
    "ax.set_xlabel(\"Store\")\n",
    "ax.set_ylabel(\"Units sold\")\n",
    "ax.legend(title=\"Product\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top three products per category\n",
    "query = \"\"\"\n",
    "    -- Total revenue by store and category\n",
    "    SELECT S.store_id,\n",
    "        S.cat_id,\n",
    "        SUM(S.sales * SP.sell_price) AS revenue\n",
    "    FROM dbo.sales_formatted AS S\n",
    "    JOIN dbo.calendar AS C ON C.d = S.d\n",
    "    JOIN dbo.sell_prices AS SP\n",
    "        ON SP.item_id = S.item_id\n",
    "        AND SP.store_id = S.store_id\n",
    "        AND SP.wm_yr_wk = C.wm_yr_wk\n",
    "    GROUP BY S.store_id, S.cat_id\n",
    "    ORDER BY S.store_id, cat_id, revenue\n",
    "\"\"\"\n",
    "revenue = pd.read_sql(query, connection)\n",
    "print(revenue.head())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "pivot = revenue.pivot(index=\"store_id\",\n",
    "                      columns=\"cat_id\",\n",
    "                      values=\"revenue\")\n",
    "pivot.plot(kind=\"bar\", ax=ax)\n",
    "\n",
    "ax.set_title(\"Total revenue per category of each store\")\n",
    "ax.set_xlabel(\"Store\")\n",
    "ax.set_ylabel(\"Units sold\")\n",
    "ax.legend(title=\"Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad24d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales per weekday\n",
    "query = \"\"\"\n",
    "    SELECT C.weekday,\n",
    "\t   SUM(S.sales) AS sum_units\n",
    "    FROM dbo.sales_formatted AS S\n",
    "    JOIN dbo.calendar AS C ON C.d = S.d\n",
    "    GROUP BY C.weekday\n",
    "    ORDER BY sum_units\n",
    "\"\"\"\n",
    "\n",
    "weekday = pd.read_sql(query, connection)\n",
    "weekday[\"sum_units\"] = (\n",
    "    round(weekday[\"sum_units\"] / 1000000, 2)\n",
    ")\n",
    "print(weekday)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(weekday[\"weekday\"],\n",
    "               weekday[\"sum_units\"],\n",
    "               color=\"#59C5FF\")\n",
    "ax.bar_label(bars, padding=3, fmt=\"%.0f\")\n",
    "ax.set_title(\"Total revenue per each weekday in millions\")\n",
    "ax.set_xlabel(\"Units sold - millions\")\n",
    "ax.set_ylabel(\"Weekday\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Week with fewer sales and week with more sales\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        COALESCE(C.event_name_1, C.event_name_2) AS event_name,\n",
    "        SUM(S.sales) AS total_units\n",
    "    FROM dbo.sales_formatted S\n",
    "    JOIN dbo.calendar C ON C.d = S.d\n",
    "    WHERE C.event_name_1 IS NOT NULL OR C.event_name_2 IS NOT NULL\n",
    "    GROUP BY COALESCE(C.event_name_1, C.event_name_2)\n",
    "    ORDER BY total_units DESC;\n",
    "\"\"\"\n",
    "\n",
    "event_sales = pd.read_sql(query, connection)\n",
    "event_sales = event_sales[1:]\n",
    "print(event_sales.head())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(event_sales[\"event_name\"],\n",
    "               event_sales[\"total_units\"],\n",
    "               color=\"#59C5FF\")\n",
    "ax.bar_label(bars, padding=3, fmt=\"%.0f\")\n",
    "ax.set_title(\"Total sales per holiday\")\n",
    "ax.set_xlabel(\"Units sold\")\n",
    "ax.set_ylabel(\"Holiday\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Percentage of revenue and sales from every store\n",
    "query = \"\"\"\n",
    "    WITH quantity_sales_per_store AS (\n",
    "        SELECT S.store_id,\n",
    "            SUM(S.sales) AS total_sales_per_store,\n",
    "            SUM(S.sales * SP.sell_price) AS total_profit_per_store\n",
    "        FROM dbo.sales_formatted AS S\n",
    "        JOIN dbo.calendar AS C ON C.d = S.d\n",
    "        JOIN dbo.sell_prices AS SP\n",
    "            ON SP.item_id = S.item_id\n",
    "            AND SP.store_id = S.store_id\n",
    "            AND SP.wm_yr_wk = C.wm_yr_wk\n",
    "        GROUP BY S.store_id\n",
    "    ), quantity_sales_overall AS (\n",
    "        SELECT SUM(S.sales) AS total_sales_overall,\n",
    "            SUM(S.sales * SP.sell_price) AS total_profit_overall\n",
    "        FROM dbo.sales_formatted AS S\n",
    "        JOIN dbo.calendar AS C ON C.d = S.d\n",
    "        JOIN dbo.sell_prices AS SP\n",
    "            ON SP.item_id = S.item_id\n",
    "            AND SP.store_id = S.store_id\n",
    "            AND SP.wm_yr_wk = C.wm_yr_wk\n",
    "    )\n",
    "    SELECT QSS.store_id,\n",
    "        ROUND(100.0 * QSS.total_sales_per_store / QSO.total_sales_overall, 2) AS total_sales_percentage,\n",
    "        ROUND(100.0 * QSS.total_profit_per_store / QSO.total_profit_overall, 2) AS total_profit_percentage\n",
    "    FROM quantity_sales_per_store AS QSS\n",
    "    CROSS JOIN quantity_sales_overall AS QSO\n",
    "    ORDER BY total_sales_percentage, total_profit_percentage;\n",
    "\"\"\"\n",
    "\n",
    "total_percentages = pd.read_sql(query, connection)\n",
    "total_percentages\n",
    "\n",
    "# Crear dos gráficos de pastel lado a lado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
    "\n",
    "# Primer pastel: porcentaje de ventas en unidades\n",
    "axes[0].pie(total_percentages[\"total_sales_percentage\"],\n",
    "            labels=total_percentages[\"store_id\"],\n",
    "            autopct=\"%.1f%%\",\n",
    "            startangle=90,\n",
    "            counterclock=False)\n",
    "axes[0].set_title(\"(%) Participation (sales)\")\n",
    "\n",
    "# Segundo pastel: porcentaje de ventas en dinero (profit)\n",
    "axes[1].pie(total_percentages[\"total_profit_percentage\"],\n",
    "            labels=total_percentages[\"store_id\"],\n",
    "            autopct=\"%.1f%%\",\n",
    "            startangle=90,\n",
    "            counterclock=False)\n",
    "axes[1].set_title(\"(%) Participation (revenue)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
